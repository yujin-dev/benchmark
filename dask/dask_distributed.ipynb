{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers = 4, threads_per_worker=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:60120\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>51.26 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:60120' processes=4 cores=16>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Future: slow_pow</b> <font color=\"gray\">status: </font><font color=\"black\">pending</font>, <font color=\"gray\">key: </font>slow_pow-ac99d921016aef5d7d5e805ba4021e7c"
      ],
      "text/plain": [
       "<Future: status: pending, key: slow_pow-ac99d921016aef5d7d5e805ba4021e7c>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Future instance object : status & results\n",
    "# dask.distributed API 는 즉시 실행됨( delayed : lazy )\n",
    "\n",
    "import time\n",
    "def slow_pow(x, y):\n",
    "    time.sleep(1)\n",
    "    return x**y\n",
    "\n",
    "res = client.submit(slow_pow, 10, 10) # pending\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.result() # rseult 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1024, 59049, 1048576, 9765625, 60466176, 282475249, 1073741824, 3486784401, 10000000000, 25937424601, 61917364224, 137858491849, 289254654976, 576650390625, 1099511627776, 2015993900449, 3570467226624, 6131066257801]\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sync 실행\n",
    "powers_of_10 = []\n",
    "for i in range(1, 20):\n",
    "    res = slow_pow(i, 10)\n",
    "    powers_of_10.append(res)\n",
    "print(powers_of_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1024, 59049, 1048576, 9765625, 60466176, 282475249, 1073741824, 3486784401, 10000000000, 25937424601, 61917364224, 137858491849, 289254654976, 576650390625, 1099511627776, 2015993900449, 3570467226624, 6131066257801]\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parallel 실행\n",
    "powers_of_10 = []\n",
    "for i in range(1, 20):\n",
    "    future = client.submit(slow_pow, i, 10)\n",
    "    powers_of_10.append(future)\n",
    "print([future.result() for future in powers_of_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1024, 59049, 1048576, 9765625]\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# map 함수 적용\n",
    "futures = client.map(slow_pow, [1,2,3,4,5], [10]*5)\n",
    "print([future.result() for future in futures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 32, 243, 1024, 3125, 7776, 16807, 32768, 59049, 100000]\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#gather\n",
    "futures = []\n",
    "for i in range(1, 11):\n",
    "    future = client.submit(slow_pow, i, 5)\n",
    "    futures.append(future)\n",
    "    \n",
    "print(client.gather(futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: finished, type: int, key: int-c0a8a20f903a4915b94db8de3ea63195>,\n",
       " <Future: status: finished, type: int, key: int-58e78e1b34eb49a68c65b54815d1b158>,\n",
       " <Future: status: finished, type: int, key: int-d3395e15f605bc35ab1bac6341a285e2>,\n",
       " <Future: status: finished, type: int, key: int-5cd9541ea58b401f115b751e79eabbff>,\n",
       " <Future: status: finished, type: int, key: int-ce9a05dd6ec76c6a6d171b0c055f3127>,\n",
       " <Future: status: finished, type: int, key: int-7ec5d3339274cee5cb507a4e4d28e791>,\n",
       " <Future: status: finished, type: int, key: int-06e5a71c9839bd98760be56f629b24cc>,\n",
       " <Future: status: finished, type: int, key: int-ea1fa36eb048f89cc9b6b045a2a731d2>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scatter : 여러 workers에 데이터를 scatter\n",
    "#data용량이 크면 worker간에 데이터를 주고 받는데 시간이 오래 걸림\n",
    "\n",
    "data_futures = client.scatter([1,2,3,4,5,6,7,8])\n",
    "data_futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "3 4\n",
      "5 6\n",
      "7 8\n",
      "[3, 7, 11, 15]\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#scatter로 실행\n",
    "def slow_add(x,y):\n",
    "    time.sleep(1)\n",
    "    return x + y\n",
    "# 인자를 future 객체로 넣어줌\n",
    "futures = []\n",
    "for i in range(0, 8, 2):\n",
    "    print(data_futures[i].result(), data_futures[i+1].result()) \n",
    "    res = client.submit(slow_add, data_futures[i], data_futures[i+1])\n",
    "    futures.append(res)\n",
    "print(client.gather(futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 27, 16, 125, 36, 343, 64, 729, 100]\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "futures = []\n",
    "for i in range(1, 31):\n",
    "    if i%2 == 0:\n",
    "        res = client.submit(slow_pow, i, 2)\n",
    "    else:\n",
    "        res = client.submit(slow_pow, i,3)\n",
    "    futures.append(res)\n",
    "print([future.result() for future in futures][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 64, 144, 729, 2197, 343, 1331, 196, 100, 16]\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# as_completed: 결과가 순서대로 끝나지 않음\n",
    "from dask.distributed import as_completed\n",
    "futures = []\n",
    "for i in range(1, 31):\n",
    "    if i%2 == 0:\n",
    "        res = client.submit(slow_pow, i, 2)\n",
    "    else:\n",
    "        res = client.submit(slow_pow, i,3)\n",
    "    futures.append(res)\n",
    "print([future.result() for future in as_completed(futures)][:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Future: status: finished, type: int, key: slow_pow-a661130857a31f92e7e16ef8afbe7d30>,\n",
      " <Future: status: finished, type: int, key: slow_pow-3ee5b2a77fd5e6964c9c48c6f905a9c5>,\n",
      " <Future: status: finished, type: int, key: slow_pow-3f5b10f27fba9db2728ee51acf0e045b>,\n",
      " <Future: status: finished, type: int, key: slow_pow-074bb042944f02473a6e1fc2cd687061>,\n",
      " <Future: status: finished, type: int, key: slow_pow-616d45ea923e8fe00f302d4ce58c9abd>,\n",
      " <Future: status: finished, type: int, key: slow_pow-3ca02fe8a7181517177d5fe18d9071a1>,\n",
      " <Future: status: finished, type: int, key: slow_pow-10177bfdd748b4557d1499fa6affe240>,\n",
      " <Future: status: finished, type: int, key: slow_pow-d5e893e74be20c0a16864ef08c5574d5>,\n",
      " <Future: status: finished, type: int, key: slow_pow-828983e218ec0a9889055c5ea3f87aec>,\n",
      " <Future: status: finished, type: int, key: slow_pow-356dbb6912017a0c1055175b51c41c18>]\n",
      "[100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000]\n",
      "Wall time: 105 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils - ERROR - '<' not supported between instances of 'NoneType' and 'tuple'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\utils.py\", line 648, in log_errors\n",
      "    yield\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 1139, in graph_doc\n",
      "    graph = GraphPlot(scheduler, sizing_mode='stretch_both')\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 615, in __init__\n",
      "    self.layout = GraphLayout(scheduler)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\graph_layout.py\", line 38, in __init__\n",
      "    priority=priority)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\graph_layout.py\", line 42, in update_graph\n",
      "    stack = sorted(dependencies, key=lambda k: priority.get(k, 0), reverse=True)\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'tuple'\n",
      "tornado.application - ERROR - Uncaught exception GET /graph (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='127.0.0.1:8787', method='GET', uri='/graph', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\web.py\", line 1592, in _execute\n",
      "    result = yield result\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\server\\views\\doc_handler.py\", line 21, in get\n",
      "    session = yield self.get_session()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\server\\views\\session_handler.py\", line 43, in get_session\n",
      "    session = yield self.application_context.create_session_if_needed(session_id, self.request)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\server\\contexts.py\", line 185, in create_session_if_needed\n",
      "    self._application.initialize_document(doc)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\application\\application.py\", line 179, in initialize_document\n",
      "    h.modify_document(doc)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\application\\handlers\\function.py\", line 134, in modify_document\n",
      "    self._func(doc)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 1139, in graph_doc\n",
      "    graph = GraphPlot(scheduler, sizing_mode='stretch_both')\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 615, in __init__\n",
      "    self.layout = GraphLayout(scheduler)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\graph_layout.py\", line 38, in __init__\n",
      "    priority=priority)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\graph_layout.py\", line 42, in update_graph\n",
      "    stack = sorted(dependencies, key=lambda k: priority.get(k, 0), reverse=True)\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'tuple'\n",
      "Exception ignored in: <function GraphPlot.__del__ at 0x00000290D12302F0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 750, in __del__\n",
      "    self.scheduler.remove_plugin(self.layout)\n",
      "AttributeError: 'GraphPlot' object has no attribute 'layout'\n",
      "distributed.utils - ERROR - '<' not supported between instances of 'NoneType' and 'tuple'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\utils.py\", line 648, in log_errors\n",
      "    yield\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 1139, in graph_doc\n",
      "    graph = GraphPlot(scheduler, sizing_mode='stretch_both')\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 615, in __init__\n",
      "    self.layout = GraphLayout(scheduler)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\graph_layout.py\", line 38, in __init__\n",
      "    priority=priority)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\graph_layout.py\", line 42, in update_graph\n",
      "    stack = sorted(dependencies, key=lambda k: priority.get(k, 0), reverse=True)\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'tuple'\n",
      "tornado.application - ERROR - Uncaught exception GET /graph (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='127.0.0.1:8787', method='GET', uri='/graph', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\web.py\", line 1592, in _execute\n",
      "    result = yield result\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\server\\views\\doc_handler.py\", line 21, in get\n",
      "    session = yield self.get_session()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\server\\views\\session_handler.py\", line 43, in get_session\n",
      "    session = yield self.application_context.create_session_if_needed(session_id, self.request)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\server\\contexts.py\", line 185, in create_session_if_needed\n",
      "    self._application.initialize_document(doc)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\application\\application.py\", line 179, in initialize_document\n",
      "    h.modify_document(doc)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bokeh\\application\\handlers\\function.py\", line 134, in modify_document\n",
      "    self._func(doc)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 1139, in graph_doc\n",
      "    graph = GraphPlot(scheduler, sizing_mode='stretch_both')\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 615, in __init__\n",
      "    self.layout = GraphLayout(scheduler)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\graph_layout.py\", line 38, in __init__\n",
      "    priority=priority)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\graph_layout.py\", line 42, in update_graph\n",
      "    stack = sorted(dependencies, key=lambda k: priority.get(k, 0), reverse=True)\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'tuple'\n",
      "Exception ignored in: <function GraphPlot.__del__ at 0x00000290D12302F0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\scheduler.py\", line 750, in __del__\n",
      "    self.scheduler.remove_plugin(self.layout)\n",
      "AttributeError: 'GraphPlot' object has no attribute 'layout'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "futures = []\n",
    "for i in range(1,11):\n",
    "    res = client.submit(slow_pow, i, 2)\n",
    "    futures.append(res)\n",
    "from pprint import pprint\n",
    "pprint(futures)\n",
    "pprint([future.result() for futures in futures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoneAndNotDoneFutures(done={<Future: status: finished, type: int, key: slow_pow-356dbb6912017a0c1055175b51c41c18>, <Future: status: finished, type: int, key: slow_pow-3ee5b2a77fd5e6964c9c48c6f905a9c5>, <Future: status: finished, type: int, key: slow_pow-828983e218ec0a9889055c5ea3f87aec>, <Future: status: finished, type: int, key: slow_pow-3ca02fe8a7181517177d5fe18d9071a1>, <Future: status: finished, type: int, key: slow_pow-3f5b10f27fba9db2728ee51acf0e045b>, <Future: status: finished, type: int, key: slow_pow-616d45ea923e8fe00f302d4ce58c9abd>, <Future: status: finished, type: int, key: slow_pow-074bb042944f02473a6e1fc2cd687061>, <Future: status: finished, type: int, key: slow_pow-d5e893e74be20c0a16864ef08c5574d5>, <Future: status: finished, type: int, key: slow_pow-10177bfdd748b4557d1499fa6affe240>, <Future: status: finished, type: int, key: slow_pow-a661130857a31f92e7e16ef8afbe7d30>}, not_done=set())\n",
      "Wall time: 3.97 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wait\n",
    "from dask.distributed import wait\n",
    "futures = []\n",
    "for i in range(1,11):\n",
    "    res = client.submit(slow_pow, i, 2)\n",
    "    futures.append(res)\n",
    "\n",
    "result_dict = wait(futures, return_when =\"ALL_COMPLETED\")\n",
    "pprint(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 4, 81, 36, 9, 25, 16, 64, 49, 1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[future.result() for future in result_dict.done][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
